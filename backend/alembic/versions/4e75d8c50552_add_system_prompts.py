"""add_system_prompts

Revision ID: 4e75d8c50552
Revises: 4b84c7bb1d2b
Create Date: 2025-12-25 15:03:23.868527

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '4e75d8c50552'
down_revision: Union[str, Sequence[str], None] = '4b84c7bb1d2b'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('system_prompts',
    sa.Column('key', sa.String(), nullable=False),
    sa.Column('text', sa.Text(), nullable=False),
    sa.Column('version', sa.Integer(), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('key')
    )
    op.create_table('tags',
    sa.Column('id', sa.String(), nullable=False),
    sa.Column('name', sa.String(), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('name')
    )
    op.create_table('note_embeddings',
    sa.Column('note_id', sa.String(), nullable=False),
    sa.Column('embedding', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['note_id'], ['notes.id'], ),
    sa.PrimaryKeyConstraint('note_id')
    )
    op.create_table('note_tags',
    sa.Column('note_id', sa.String(), nullable=True),
    sa.Column('tag_id', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['note_id'], ['notes.id'], ),
    sa.ForeignKeyConstraint(['tag_id'], ['tags.id'], )
    )
    op.alter_column('integration_logs', 'integration_id',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('integration_logs', 'note_id',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('integration_logs', 'status',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.add_column('integrations', sa.Column('config', sa.JSON(), nullable=True))
    op.add_column('integrations', sa.Column('is_active', sa.Boolean(), nullable=True))
    op.alter_column('integrations', 'access_token',
               existing_type=postgresql.BYTEA(),
               type_=sa.String(),
               existing_nullable=False)
    op.alter_column('integrations', 'refresh_token',
               existing_type=postgresql.BYTEA(),
               type_=sa.String(),
               existing_nullable=True)
    op.drop_column('integrations', 'settings')
    op.add_column('notes', sa.Column('is_favorite', sa.Boolean(), nullable=True))
    op.alter_column('notes', 'audio_url',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('notes', 'processing_error',
               existing_type=sa.VARCHAR(),
               type_=sa.Text(),
               existing_nullable=True)
    op.drop_column('notes', 'updated_at')
    op.drop_column('plans', 'created_at')
    op.alter_column('users', 'hashed_password',
               existing_type=sa.VARCHAR(),
               nullable=False)
    # op.drop_index(op.f('ix_users_api_key'), table_name='users')
    # op.drop_index(op.f('ix_users_telegram_chat_id'), table_name='users')
    # op.drop_column('users', 'api_key')
    # op.drop_column('users', 'first_name')
    # op.drop_column('users', 'oauth_accounts')
    # op.drop_column('users', 'has_onboarded')
    # op.drop_column('users', 'reset_token')
    # op.drop_column('users', 'reset_token')
    # op.drop_column('users', 'language')
    
    # --- Seed System Prompts ---
    op.execute("""
    INSERT INTO system_prompts (key, text, version) VALUES 
    ('general_analysis', 'You are an advanced AI assistant powered by DeepSeek V3. Analyze the user''s audio transcription. Return a valid JSON object with the following fields:\n1. ''title'': A short, catchy, creative title.\n2. ''summary'': A markdown formatted summary with bullet points and sections.\n3. ''action_items'': A list of actionable tasks (strings), e.g., [''Buy milk'', ''Email John'']. Empty if none.\n4. ''tags'': A list of 3-7 automatic tags.\n5. ''mood'': One word describing the mood.\n6. ''calendar_events'': A list of objects { ''title'': str, ''date'': str (ISO or description), ''time'': str } if any dates/times are mentioned. Empty list if none.\n7. ''diarization'': A list of objects { ''speaker'': str, ''text'': str } representing the conversation flow.\n8. ''health_data'': A structured object for Apple Health export. If relevant data is found, return { ''nutrition'': { ''calories'': int, ''protein'': int, ''carbs'': int, ''fat'': int, ''water_ml'': int, ''name'': str }, ''workout'': { ''type'': str, ''duration_minutes'': int, ''calories_burned'': int }, ''symptoms'': [str] }. If no health data, return null.\n9. ''intent'': Classify the primary intent into one of: [''task'', ''event'', ''note'', ''crm'', ''journal'', ''shopping'', ''idea''].\n10. ''suggested_project'': Guess the project context (e.g., ''Work'', ''Home'', ''Startup'', ''Health'', ''Travel'').\n11. ''entities'': A list of strings (people, places, specific companies/products mentioned) for linking.\n12. ''priority'': Integer from 1 (High/Urgent) to 4 (Low/Someday).\n13. ''notion_properties'': A JSON object guessing properties for a Notion database entry (e.g. {''Status'': ''In Progress'', ''Category'': ''Research''}).\n14. ''explicit_destination_app'': Detect if the user explicitly specifies a destination in the voice command. One of [''todoist'', ''notion'', ''slack'', ''google_calendar'', ''google_drive'', ''dropbox'', ''email''] or null if none mentioned.\n15. ''explicit_folder'': Extract the specific folder, project, or database name mentioned (e.g., ''Work'', ''Journal'', ''Home'') or null.\n\nCRITICAL: The ''summary'' and ''action_items'' fields must NOT contain the routing command itself (e.g., ''send this to Todoist'', ''put this in my work project''). Clean the text by removing these instructions.', 1),
    ('extract_health', 'You are a Health Data Assistant. Analyze the text for health and fitness metrics. Extract specific values like ''Steps'', ''Weight'', ''Sleep Duration'', ''Distance Ran'', ''Water Intake'', ''Heart Rate''. Return a JSON object where keys are metric names (e.g., ''Weight'', ''Steps'') and values are strings with units (e.g., ''75 kg'', ''8500 steps''). \n\nCompare with previous data: {prev_health_json}. If there is a positive trend (e.g. weight drop, run distance increased, more water), add a field ''trend_compliment'': ''Keep it up! Down 2kg since last time.'' or similar. Ensure the output is strictly valid JSON.', 1),
    ('ask_notes', 'You are VoiceBrain, a helpful AI assistant. Answer the user''s question using ONLY the provided context from their notes. If the answer is not in the context, say ''I couldn''t find that information in your notes.'' Keep answers concise and friendly.', 1);
    """)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('users', sa.Column('language', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('reset_token', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('has_onboarded', sa.BOOLEAN(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('oauth_accounts', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('first_name', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('api_key', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.create_index(op.f('ix_users_telegram_chat_id'), 'users', ['telegram_chat_id'], unique=True)
    op.create_index(op.f('ix_users_api_key'), 'users', ['api_key'], unique=True)
    op.alter_column('users', 'hashed_password',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.add_column('plans', sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True))
    op.add_column('notes', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.alter_column('notes', 'processing_error',
               existing_type=sa.Text(),
               type_=sa.VARCHAR(),
               existing_nullable=True)
    op.alter_column('notes', 'audio_url',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.drop_column('notes', 'is_favorite')
    op.add_column('integrations', sa.Column('settings', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.alter_column('integrations', 'refresh_token',
               existing_type=sa.String(),
               type_=postgresql.BYTEA(),
               existing_nullable=True)
    op.alter_column('integrations', 'access_token',
               existing_type=sa.String(),
               type_=postgresql.BYTEA(),
               existing_nullable=False)
    op.drop_column('integrations', 'is_active')
    op.drop_column('integrations', 'config')
    op.alter_column('integration_logs', 'status',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.alter_column('integration_logs', 'note_id',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.alter_column('integration_logs', 'integration_id',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.drop_table('note_tags')
    op.drop_table('note_embeddings')
    op.drop_table('tags')
    op.drop_table('system_prompts')
    # ### end Alembic commands ###
